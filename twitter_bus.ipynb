{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter bus.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wadh5811/Fall-21-Research/blob/main/twitter_bus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkAGL6YzpVFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f86b7a8-d977-41b7-db04-134904360563"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF80rCRT9iwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8806edd8-9197-4986-df03-bdb2fd42d59d"
      },
      "source": [
        "!pip install snscrape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snscrape\n",
            "  Downloading snscrape-0.3.4-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhSB5n89Q_pK",
        "outputId": "e7cdaf55-3743-4880-8634-626ff64a8acd"
      },
      "source": [
        "%cd /content/\n",
        "%mkdir /content/raw_data_bus\n",
        "%ls\n",
        "# import os\n",
        "# dir = '/content/raw_data'\n",
        "# for f in os.listdir(dir):\n",
        "#     os.remove(os.path.join(dir, f))\n",
        "# os.rename('raw_data', 'raw_data_bus')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34mraw_data_bus\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zf0O6skLve5"
      },
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "geolocator = Nominatim(user_agent=\"me\")\n",
        "geolocator.geocode(\"New York, United States\").raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilCOzwYc9omF"
      },
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "geocode:\"{coordinates}\" \n",
        "lang:\"{language}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-fvBmJC9hXp"
      },
      "source": [
        "keywords=['bus']\n",
        "coordinates = '40.7127281,-74.0060152, 50mi',\n",
        "languages=['en']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pIq8PBl-DIO"
      },
      "source": [
        "# sntwitter.TwitterSearchScraper(f'{keywords} + since:{start} until:{end}')\n",
        "# tweets_list = []\n",
        "# keywords = 'bus OR buses OR ferry OR ferries OR \"public transportation\" OR \"public transport\"'\n",
        "\n",
        "# for i, tweet in enumerate(sntwitter.TwitterSearchScraper(keywords + ' since:2020-01-01 until:2020-01-02 geocode:\"40.730610,-73.935242, 50mi\" lang:en').get_items()):\n",
        "#     username = tweet.username\n",
        "#     text = tweet.content\n",
        "#     pubdate = tweet.date\n",
        "#     permalink = tweet.url\n",
        "#     tweets_list.append([username, text, pubdate, permalink])\n",
        "\n",
        "# tweets_df = pd.DataFrame(tweets_list, columns = ['username', 'text', 'date', 'link'])\n",
        "# tweets_df.text[1]\n",
        "# start_date.strftime(\"%Y-%m-%d\") + '.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCi6fslqCXWV",
        "outputId": "f9a0572a-d222-4259-cd6c-10ea97150ca1"
      },
      "source": [
        "from snscrape.base import ScraperException\n",
        "scraper_exception_bus = 0\n",
        "date_start_bus = \"2021-06-02\"\n",
        "while date_start_bus != \"2021-12-26\":\n",
        "  try:\n",
        "    start_dates = pd.date_range(start=date_start_bus,end=\"2021-12-26\")\n",
        "    import datetime\n",
        "    keywords = 'bus OR buses OR ferry OR ferries OR \"public transportation\" OR \"public transport\" OR Greyhound OR megabus OR boltbus OR \"Peter Pan bus\" OR Lizak OR boltbus OR VAMOOSE OR \"TRIPPER BUS\" OR \"airport shuttle\" OR \"air shuttle\" OR \"shuttle bus\"'\n",
        "    length = []\n",
        "    counter = 0\n",
        "    for start_date in start_dates:\n",
        "        since = start_date.strftime(\"%Y-%m-%d\")\n",
        "        until = (start_date+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "        search_txt = keywords + ' since:' + since + ' until:' + until + ' geocode:\"40.730610,-73.935242, 50mi\" lang:en'\n",
        "        tweets_list = []\n",
        "        for i, tweet in enumerate(sntwitter.TwitterSearchScraper(search_txt).get_items()):\n",
        "            username = tweet.username\n",
        "            text = tweet.content\n",
        "            pubdate = tweet.date\n",
        "            permalink = tweet.url\n",
        "            tweets_list.append([username, text, pubdate, permalink])\n",
        "        length.append(len(tweets_list))\n",
        "        counter += 1\n",
        "        if counter % 100 == 0:\n",
        "            print(max(length))\n",
        "        tweets_df = pd.DataFrame(tweets_list, columns = ['username', 'text', 'date', 'link'])\n",
        "        tweets_df.to_csv('/content/raw_data_bus/' + since + '.csv')\n",
        "        date_start_bus = since\n",
        "  except ScraperException:\n",
        "    scraper_exception_bus+=1\n",
        "\n",
        "print(scraper_exception_bus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Error retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_composer_source=true&include_ext_alt_text=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=bus+OR+buses+OR+ferry+OR+ferries+OR+%22public+transportation%22+OR+%22public+transport%22+OR+Greyhound+OR+megabus+OR+boltbus+OR+%22Peter+Pan+bus%22+OR+Lizak+OR+boltbus+OR+VAMOOSE+OR+%22TRIPPER+BUS%22+OR+%22airport+shuttle%22+OR+%22air+shuttle%22+OR+%22shuttle+bus%22+since%3A2021-08-03+until%3A2021-08-04+geocode%3A%2240.730610%2C-73.935242%2C+50mi%22+lang%3Aen&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&cursor=scroll%3AthGAVUV0VFVBaEwL2N8KjyvScWkoCy8dn2ur4nEnEV4IJ6FYCJehgHREVGQVVMVDUBFQIVAAA%3D&pc=1&spelling_corrections=1&ext=mediaStats%252CcameraMoment: ConnectionError(ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))), retrying\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQxV0w21TlBC",
        "outputId": "024139e1-99ac-4173-b78f-ce66e4889d3c"
      },
      "source": [
        "start_dates = pd.date_range(start=\"2020-01-01\",end=\"2020-02-01\")\n",
        "for start_date in start_dates:\n",
        "    print(start_date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-01-01 00:00:00\n",
            "2020-01-02 00:00:00\n",
            "2020-01-03 00:00:00\n",
            "2020-01-04 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-06 00:00:00\n",
            "2020-01-07 00:00:00\n",
            "2020-01-08 00:00:00\n",
            "2020-01-09 00:00:00\n",
            "2020-01-10 00:00:00\n",
            "2020-01-11 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-13 00:00:00\n",
            "2020-01-14 00:00:00\n",
            "2020-01-15 00:00:00\n",
            "2020-01-16 00:00:00\n",
            "2020-01-17 00:00:00\n",
            "2020-01-18 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-20 00:00:00\n",
            "2020-01-21 00:00:00\n",
            "2020-01-22 00:00:00\n",
            "2020-01-23 00:00:00\n",
            "2020-01-24 00:00:00\n",
            "2020-01-25 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-01-27 00:00:00\n",
            "2020-01-28 00:00:00\n",
            "2020-01-29 00:00:00\n",
            "2020-01-30 00:00:00\n",
            "2020-01-31 00:00:00\n",
            "2020-02-01 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l80-xS9osix"
      },
      "source": [
        "!cp -r raw_data_bus gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgAfosiyAGSk"
      },
      "source": [
        "keyword = '(COVID OR Corona Vírus)'\n",
        "maxTweets = 3000\n",
        "tweets = []\n",
        "tdf = None\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(keyword + ' since:2020-01-01 until:2021-01-01 lang:en').get_items()) :\n",
        "        if i > maxTweets :\n",
        "            break\n",
        "        username = tweet.username\n",
        "        text = tweet.content\n",
        "        pubdate = tweet.date\n",
        "        permalink = tweet.url\n",
        "        tweets.append({\n",
        "            \"permalink\":permalink,\n",
        "            \"pubdate\":pubdate,\n",
        "            \"text\":text,\n",
        "            \"username\":username\n",
        "        })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM_cBVdfAIHj",
        "outputId": "1b11521e-ec67-48e1-8ebf-68296670b326"
      },
      "source": [
        "tweets[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'permalink': 'https://twitter.com/annabarros/status/1344440739917406211',\n",
              " 'pubdate': datetime.datetime(2020, 12, 31, 0, 30, 25, tzinfo=datetime.timezone.utc),\n",
              " 'text': 'Triste demais com o falecimento de @guroman por covid. Sempre querido comigo. Vírus maldito.',\n",
              " 'username': 'annabarros'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA-nthj4BTtG"
      },
      "source": [
        "search_words = [('bike OR #bike OR bicycle OR #bicycle'),\n",
        "                ('citibike OR \"citi bike\" OR \"bike share\"'),\n",
        "                ('jumpbike OR \"jump bike\" OR \"bike share\"'),\n",
        "                ('uber OR #uber OR #Uber OR lyft OR #lyft OR #Lyft'),\n",
        "                ('subway OR subways OR metroline OR PATH OR Amtrak OR MTA OR LIRR OR shuttle OR train OR trains OR \"light rail\" OR \"light rails\"'),\n",
        "                ('bus OR buses OR ferry OR ferries OR \"public transportation\" OR \"public transport\"'),\n",
        "                ('Greyhound OR megabus OR boltbus OR \"Peter Pan bus\" OR Lizak OR boltbus OR VAMOOSE OR \"TRIPPER BUS\" OR \"airport shuttle\" OR \"air shuttle\" OR \"shuttle bus\"'),\n",
        "                ('\"cab\" OR \"cabs\" OR \"taxi\" OR taxis OR car OR cars OR scooter OR scooters OR \"parking\" OR \"private car\"'),\n",
        "                ('DOT OR \"Department of Transportation\"'),\n",
        "                ('Walmart OR Target OR \"Whole Foods\" OR Safeway OR Mcdonald OR KFC OR Popeyes OR \"Burger King\"' ),\n",
        "                ('motorbike OR motorbikes OR dirtbike OR dirtbikes'),\n",
        "                ('\"social distance\" OR #socialdistance OR \"COVID\" OR \"COVID-19\" OR \"face mask\" OR \"public health\"'),\n",
        "                ('\"Return to work\" OR \"return to office\" OR \"back to office\" OR \"back to work\"'),\n",
        "                ('#WFH OR #Workfromhome OR #Reomotework OR \"work from work\" OR \"remote work\"'),\n",
        "                ('\"telecommuting\" OR \"Zoom\" OR \"skype\" OR #telecommuting OR #Zoom OR #skype')]\n",
        "\n",
        "list_names = ['bike', 'citibike', 'jumpbike', 'uber', 'subway', 'bus', 'shuttle', 'cab', 'DOT',\n",
        "              'Walmart', 'motorbike', 'COVID', 'Returnwork', 'WFH', 'telecommuting']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}