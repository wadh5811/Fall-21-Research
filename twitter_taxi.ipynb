{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter taxi.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wadh5811/Fall-21-Research/blob/main/twitter_taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkAGL6YzpVFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0917b3a4-77f5-4c87-e5b6-b404c57868b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #install Anaconda3\n",
        "# !wget -qO ac.sh https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh \n",
        "# !bash ./ac.sh -b\n",
        "# !pip install pyngrok -q\n",
        "# !pip install jsonlines\n",
        "\n",
        "# !/root/anaconda3/bin/pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
        "# !/root/anaconda3/bin/pip3 install --upgrade git+https://github.com/JustAnotherArchivist/snscrape@master\n"
      ],
      "metadata": {
        "id": "JVLjjOivxvpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF80rCRT9iwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ed122f-450f-46e3-c5b7-8bfbe9294c57"
      },
      "source": [
        "!pip install snscrape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snscrape\n",
            "  Downloading snscrape-0.3.4-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhSB5n89Q_pK",
        "outputId": "52d2c299-e074-42e7-f023-b4ad1ceea59f"
      },
      "source": [
        "%cd /content/\n",
        "%mkdir /content/raw_data_taxi\n",
        "%ls\n",
        "# import os\n",
        "# dir = '/content/raw_data'\n",
        "# for f in os.listdir(dir):\n",
        "#     os.remove(os.path.join(dir, f))\n",
        "# os.rename('raw_data', 'raw_data_bus')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34mraw_data_taxi\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zf0O6skLve5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a530109-0e28-46b3-9117-4f2ea03cc58a"
      },
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "geolocator = Nominatim(user_agent=\"me\")\n",
        "geolocator.geocode(\"New York, United States\").raw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boundingbox': ['40.477399', '40.9161785', '-74.25909', '-73.7001809'],\n",
              " 'class': 'boundary',\n",
              " 'display_name': 'New York, United States',\n",
              " 'icon': 'https://nominatim.openstreetmap.org/ui/mapicons//poi_boundary_administrative.p.20.png',\n",
              " 'importance': 1.2175766114518463,\n",
              " 'lat': '40.7127281',\n",
              " 'licence': 'Data Â© OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright',\n",
              " 'lon': '-74.0060152',\n",
              " 'osm_id': 175905,\n",
              " 'osm_type': 'relation',\n",
              " 'place_id': 282582851,\n",
              " 'type': 'administrative'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilCOzwYc9omF"
      },
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "geocode:\"{coordinates}\" \n",
        "lang:\"{language}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJSQ_zZs9oqj"
      },
      "source": [
        "# sntwitter.TwitterSearchScraper(f'{keywords} + since:{start} until:{end}')\n",
        "# tweets_list = []\n",
        "# keywords = 'bus OR buses OR ferry OR ferries OR \"public transportation\" OR \"public transport\"'\n",
        "\n",
        "# for i, tweet in enumerate(sntwitter.TwitterSearchScraper(keywords + ' since:2020-01-01 until:2020-01-02 geocode:\"40.730610,-73.935242, 50mi\" lang:en').get_items()):\n",
        "#     username = tweet.username\n",
        "#     text = tweet.content\n",
        "#     pubdate = tweet.date\n",
        "#     permalink = tweet.url\n",
        "#     tweets_list.append([username, text, pubdate, permalink])\n",
        "\n",
        "# tweets_df = pd.DataFrame(tweets_list, columns = ['username', 'text', 'date', 'link'])\n",
        "# tweets_df.text[1]\n",
        "# start_date.strftime(\"%Y-%m-%d\") + '.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCi6fslqCXWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155abe18-76e0-4d0c-e54c-ebc38708292d"
      },
      "source": [
        "from snscrape.base import ScraperException\n",
        "scraper_exception_taxi = 0\n",
        "date_start_taxi = \"2021-06-02\"\n",
        "while date_start_taxi != \"2021-12-26\":\n",
        "  try:\n",
        "    start_dates = pd.date_range(start=date_start_taxi,end=\"2021-12-26\")\n",
        "    import datetime\n",
        "    keywords = 'uber OR #uber OR #Uber OR lyft OR #lyft OR #Lyft OR \"cab\" OR \"cabs\" OR \"taxi\" OR taxis'\n",
        "    length = []\n",
        "    counter = 0\n",
        "    for start_date in start_dates:\n",
        "        since = start_date.strftime(\"%Y-%m-%d\")\n",
        "        until = (start_date+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "        search_txt = keywords + ' since:' + since + ' until:' + until + ' geocode:\"40.730610,-73.935242, 50mi\" lang:en'\n",
        "        tweets_list = []\n",
        "        for i, tweet in enumerate(sntwitter.TwitterSearchScraper(search_txt).get_items()):\n",
        "            username = tweet.username\n",
        "            text = tweet.content\n",
        "            pubdate = tweet.date\n",
        "            permalink = tweet.url\n",
        "            tweets_list.append([username, text, pubdate, permalink])\n",
        "        length.append(len(tweets_list))\n",
        "        counter += 1\n",
        "        if counter % 100 == 0:\n",
        "            print(max(length))\n",
        "        tweets_df = pd.DataFrame(tweets_list, columns = ['username', 'text', 'date', 'link'])\n",
        "        tweets_df.to_csv('/content/raw_data_taxi/' + since + '.csv')\n",
        "        date_start_taxi = since\n",
        "  except ScraperException:\n",
        "    scraper_exception_taxi+=1\n",
        "\n",
        "print(scraper_exception_taxi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQxV0w21TlBC"
      },
      "source": [
        "start_dates = pd.date_range(start=\"2021-06-02\",end=\"2021-12-16\")\n",
        "for start_date in start_dates:\n",
        "    print(start_date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l80-xS9osix"
      },
      "source": [
        "!cp -r raw_data_taxi gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgAfosiyAGSk"
      },
      "source": [
        "# keyword = '(COVID OR Corona VÃ­rus)'\n",
        "# maxTweets = 3000\n",
        "# tweets = []\n",
        "# tdf = None\n",
        "# for i,tweet in enumerate(sntwitter.TwitterSearchScraper(keyword + ' since:2020-01-01 until:2021-01-01 lang:en').get_items()) :\n",
        "#         if i > maxTweets :\n",
        "#             break\n",
        "#         username = tweet.username\n",
        "#         text = tweet.content\n",
        "#         pubdate = tweet.date\n",
        "#         permalink = tweet.url\n",
        "#         tweets.append({\n",
        "#             \"permalink\":permalink,\n",
        "#             \"pubdate\":pubdate,\n",
        "#             \"text\":text,\n",
        "#             \"username\":username\n",
        "#         })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM_cBVdfAIHj",
        "outputId": "1b11521e-ec67-48e1-8ebf-68296670b326"
      },
      "source": [
        "# tweets[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'permalink': 'https://twitter.com/annabarros/status/1344440739917406211',\n",
              " 'pubdate': datetime.datetime(2020, 12, 31, 0, 30, 25, tzinfo=datetime.timezone.utc),\n",
              " 'text': 'Triste demais com o falecimento de @guroman por covid. Sempre querido comigo. VÃ­rus maldito.',\n",
              " 'username': 'annabarros'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA-nthj4BTtG"
      },
      "source": [
        "search_words = [('bike OR #bike OR bicycle OR #bicycle'),\n",
        "                ('citibike OR \"citi bike\" OR \"bike share\"'),\n",
        "                ('jumpbike OR \"jump bike\" OR \"bike share\"'),\n",
        "                ('uber OR #uber OR #Uber OR lyft OR #lyft OR #Lyft'),\n",
        "                ('subway OR subways OR metroline OR PATH OR Amtrak OR MTA OR LIRR OR shuttle OR train OR trains OR \"light rail\" OR \"light rails\"'),\n",
        "                ('bus OR buses OR ferry OR ferries OR \"public transportation\" OR \"public transport\"'),\n",
        "                ('Greyhound OR megabus OR boltbus OR \"Peter Pan bus\" OR Lizak OR boltbus OR VAMOOSE OR \"TRIPPER BUS\" OR \"airport shuttle\" OR \"air shuttle\" OR \"shuttle bus\"'),\n",
        "                ('\"cab\" OR \"cabs\" OR \"taxi\" OR taxis OR car OR cars OR scooter OR scooters OR \"parking\" OR \"private car\"'),\n",
        "                ('DOT OR \"Department of Transportation\"'),\n",
        "                ('Walmart OR Target OR \"Whole Foods\" OR Safeway OR Mcdonald OR KFC OR Popeyes OR \"Burger King\"' ),\n",
        "                ('motorbike OR motorbikes OR dirtbike OR dirtbikes'),\n",
        "                ('\"social distance\" OR #socialdistance OR \"COVID\" OR \"COVID-19\" OR \"face mask\" OR \"public health\"'),\n",
        "                ('\"Return to work\" OR \"return to office\" OR \"back to office\" OR \"back to work\"'),\n",
        "                ('#WFH OR #Workfromhome OR #Reomotework OR \"work from work\" OR \"remote work\"'),\n",
        "                ('\"telecommuting\" OR \"Zoom\" OR \"skype\" OR #telecommuting OR #Zoom OR #skype')]\n",
        "\n",
        "list_names = ['bike', 'citibike', 'jumpbike', 'uber', 'subway', 'bus', 'shuttle', 'cab', 'DOT',\n",
        "              'Walmart', 'motorbike', 'COVID', 'Returnwork', 'WFH', 'telecommuting']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}